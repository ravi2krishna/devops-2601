7th Jan 2026
============

    -> What Is DevOps ?

        -> DevOps is a set of "PRACTICES" that works to "AUTOMATE" and "INTEGRATE" 
        the processes between Software Development (Dev) and IT Operations(Ops) teams.

    -> Development Team

        -> To "Build Applications" We need Roles Like 

                -> Software Architect 
                -> System Engineer
                -> Software Developers 
                -> Software Testers 
                -> etc 

    -> Operations Team

        -> To "Build Infrastructure" & Maintain Applications, We need Roles Like 

                -> System Admin 
                -> Network Admin 
                -> Cloud Admin 
                -> Security Admin 
                -> etc 

    -> DevOps Engineer

        -> DevOps Engineers will implement a set of "PRACTICES" using "TOOLS" so that 
        organizations can build, test, and deploy [ DELIVERY LINE ] software 
        faster and more reliably.

    
    -> DevOps PRACTICES     ==>     "TOOLS" 

        -> Version Control Systems (VCS) ==> Git

            -> For Tracking Code 

            -> Happens Inside Developer Laptop - Local To Individual Developer

        -> Source Code Management (SCM) ==> GitHub 

            -> Store Multiple Versions Of Code 

            -> Happens Inside Organization - Central to All Developer

        -> Containerization ==> Docker 

            -> To Get Acceleration (FASTER) 

        -> Orchestration ==> Kubernetes  

            -> To Get Reliability 
            
            -> Helps Run Applications Without Downtime (Run 24 X 7) - Production Environments 

        -> Continuous Integration & Continuous Deployment (CI-CD) ==> GitHub Actions 

            -> To Get Automation In Repetitive Tasks   

    -> DevOps Prerequisites 

        -> Application - Project

            -> SDLC - Software Development Life Cycle 

                -> Requirement -> Design -> Code -> "Build" -> Test -> Release -> "Deploy" 

        -> Servers (AWS & AZURE) - Charges (4 INR Per Hour) 

        -> Command Line Interface - CLI (Linux Commands)

    -> As a DevOps Engineer You are responsible for     

        -> Implement Automation

        -> Implement Acceleration (Fastness)

        -> Implement Reliability (Application Should Always Run)

    
    -> When we start building/developing a project 

        -> SDLC 

            -> The Software Development Life Cycle (SDLC) is a process followed by 
            software development teams to design, develop and test high-quality software. 

            -> The SDLC consists of multiple stages such as 

                -> Requirement -> Design -> Code -> "Build" -> Test -> Release -> "Deploy" 

                -> NOTE: From DevOps Context 

                    -> Code -> "Build" -> Test -> "Deploy" 

                    -> "Build" & "Deploy" Applications On Servers 

        -> Requirement

            -> Build LMS (Learning Management System): Manage Courses 

                -> Three Tier App Architecture

                    -> One thing the most visited websites have in common is that they are dynamic websites.
                    Their development typically involves server-side coding, client-side coding and 
                    database technology.

            -> Most Popular Applications
                
                -> https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites

        -> Code 

            -> Developers will use "Git" to track code and eventually "Push" Code to "GitHub" 

        

9th Jan 2026
============

    -> LMS Project 

    -> "DEVELOPMENT" team

        -> DEVELOPMENT Team mainly builds Applications 

        -> DEVELOPMENT Means Coding 

    -> Version Control Systems (VCS)

        ->  Version control / Revision control / Source control
            is a process that helps to "keep track of changes" made to 
            files (computer programs, web site files, documents etc)

        -> https://www.sirhow.com/uploads/2023/07/check-gpay-transaction-history-step-4.jpg

        -> Advantage Of VCS is Revert Changes To Previous Working Versions, 
            if there are issues in new version

            -> TransactionIDs == Commit IDs 

    -> To Implement Version Control System we need "Git" Software 

        -> Git helps in tracking code / changes in your code 

        -> Git tracks code in your laptop 

        -> Git will generate commit id for every change we make (like every transaction me make in UPI)


    -> All the transactions made will be stored in Server, similarly we store all our
    commit id's in Source Code Management(SCM) like a Server 

        -> NOTE: Mobile Phone -> GooglePay -> Bank Server(TransactionIDs)

        -> NOTE: Laptop -> Git -> GitHub(Commit IDs )

    -> GitHub - Server Side Software  - Organizations

            -> GitHub provides a platform to store code and it's versions 

            -> GitHub Stores All Versions Of Code in centralized location (github.com)    

    -> NOTE: Example of Real World Application

        -> https://notepad-plus-plus.org/downloads/ - APP

        -> https://github.com/notepad-plus-plus/notepad-plus-plus - CODE

        -> https://github.com/notepad-plus-plus/notepad-plus-plus/graphs/contributors - HISTORY 

        -> https://github.com/notepad-plus-plus/notepad-plus-plus/commits/master/ - Commits 

    -> Repository 

        -> A repository contains all of your "project's files" and each file's revision history. 
        Developers can discuss and manage your project's work within the repository.

            -> https://github.com/notepad-plus-plus/notepad-plus-plus

            -> https://github.com/notepad-plus-plus/notepad-plus-plus/tags


    -> JIRA (Proprietary)

        -> Jira is a proprietary product developed by Atlassian that allows 
        bug tracking, issue tracking and agile project management. 

        -> https://images.ctfassets.net/xjcz23wx147q/2vuHCsAF3tUpzYykEb9GAX/11fb10694a339636aceb9f531f11e49f/Kanban-updated.png

    -> GitHub Projects & Issues (FREE)

            -> GitHub Projects are a feature within GitHub designed for planning and tracking work

            -> GitHub Issues is a built-in, lightweight issue-tracking system in every repository 
                used for planning, discussing, and tracking work like 
                bug reports, new features, and tasks.

            -> NOTE: Within Project we have Issues 

    -> Start LMS Project (Development - Developer)   

        -> Create GitHub Account - https://github.com/
        -> Create Repository
        -> Assign Work To Developers - Projects & Issues On GitHub 
        -> Developers Will Start Coding - Versioning Starts 
        -> Developers Will Update Code To GitHub Repository   

    -> Start LMS Project (Development - Developer)   

        -> Create GitHub Account - https://github.com/
        -> Create Repository - https://github.com/ravi2krishna/login-2601.git
        -> Assign Work To Developers - Projects & Issues On GitHub 
            -> https://github.com/ravi2krishna/login-2601/projects?query=is%3Aopen
            -> https://github.com/ravi2krishna/login-2601/issues
        -> Developers Will Start Coding - Versioning Starts 
            -> Install Git Software for Versioning
                -> Open GitBash 
                -> Setting the git Configuration
                    -> git config --global user.name "ravi2krishna"
                    -> git config --global user.email "ravi2krishna@gmail.com"
            -> Install Visual Studio Code (VSCode) to Write Code 
            -> Implement(Start Coding) Issue / Feature Assigned to him 
        -> Developers Will Update Code To GitHub Repository


12th Jan 2026
==============

    -> Implement(Start Coding) Issue / Feature Assigned to him 

    -> Developers Will Update Code To GitHub Repository

    -> Currently the Application is on GitHub 

    -> Can customers / clients access the Application from Github ?

        -> NO 

    -> We need Servers To Host / To Deploy Applications so that 
    customers / clients access the Application

    -> Operations Related Work
    
    -> Servers 

        -> A Server is a "computer system" that provides data or services 
            to others computers, known as "clients" over a network.

        -> Laptop can be used by one person at a time 
        
        -> Server can be used by multiple persons(clients) at a time 

    -> Physical Server 

        -> Physical Server Consists Of "Hardware" + "Operating System" (Linux OS - Ubuntu)

        -> CPU(Processor) + RAM + HDD + N/W Card
    
    -> Server Softwares 

        -> Web Server : Hosts and Serves Web Pages / Web Applications Over Internet 

            -> Examples : Apache Web Server, Nginx Web Server, IIS Server etc 

        -> Database Server : Hosts Application Data & Transactions

            -> Examples : MySQL Server, Postgres Server, MS SQL Server etc 

        -> Email Server : Software that sends, receives, and stores emails.

            -> Examples : Postfix Server, SendMail, Send grid etc 


    -> Where To get servers from ?

        -> Purchase Server 

            -> Purchasing Servers is QUITE COSTLY and from learning perspective we cannot
                afford a server 

            -> Rather than Purchasing Server, we want to "RENT SERVERS" 
        
        -> As per example discussed 

            -> Buying Server == Buying Bike 

            -> Renting Server == Renting Bike 

            -> Renting Bike : Pay for how many kilometers you traveled 

            -> Renting Server : Pay for how much you use i.e "PAY AS YOU GO" price model

                -> 1 Server for 1 hour 
                -> 1 Server for 5 hour 
                -> 1 Server for 5 days 

            -> Where can i rent bike ?

                -> Ola, Uber, Rapido etc 

            -> Where can i rent server ?

                -> AWS, AZURE, GCP, OCI etc

    -> Cloud Computing 

        -> Cloud computing is the "on-demand" delivery of "IT resources" 
        like servers, storage, and software over the "internet" 
        on a "pay-as-you-go" basis.

    -> In our course will implement servers on both "AWS" & "AZURE"

        -> AWS Cloud - FREE TRAIL - 6 Months - $200

        -> AZURE Cloud - FREE TRAIL - 1 Month - $200

    
    -> AWS Account Setup - LABS 
        
        Visit - https://aws.amazon.com/free

    -> AZURE Account Setup - LABS
        
        Visit - https://azure.microsoft.com/en-us/free/

    -> Following Details Required - Cloud Setup

        Unique Email ID
        Unique Mobile Number
        Unique PAN CARD
        Unique Debit / Credit Card

19th Jan 2026
==============

    -> AWS Server Setup 

        -> Amazon Elastic Compute Cloud(EC2) is a part of Amazon's cloud-computing platform, 
        Amazon Web Services, that "allows users to rent virtual computers(servers)" 
        on which to run their "own computer applications".

        -> Server                   ==> AWS EC2 Instance 
        -> Server Name              ==> Instance Name 
        -> Operating System         ==> AMI - Amazon Machine Image (Linux Ubuntu 22.04)
        -> CPU + RAM                ==> Instance Types(t2.micro, t2.medium etc)           
        -> Login / Authentication   ==> Key Pairs (Public Key & Private Key)
        -> Network                  ==> VPC(Virtual Private Cloud)
        -> Firewall                 ==> Security Group (Rules: Protocol, Port, Source)
        -> Storage (Hard Disk)      ==> EBS Volume (Elastic Block Storage) is 8 GB 

        -> Login To AWS 

            -> https://aws.amazon.com/console/ 


    -> Firewall 
    
        -> A firewall is a network security system that monitors and controls 
            incoming and outgoing network traffic based on predetermined security rules (protocols) 

        -> SSH Protocol (Secure Shell)

            -> Is a network protocol used for secure remote access to 
                computers over an unsecured network.

            -> SSH allows users to log in, run commands and transfer files securely.

            -> SSH typically runs on TCP port 22

    -> How To Connect With Server ?

        -> SSH Client Softwares 

            -> A software program which uses SSH to connect with remote linux server 

            -> From Online 
                
                -> https://ssheasy.com/

            -> From Laptop / System Use any one of the below Software 

                -> GitBash (recommended) it provides ssh & also git 
                -> Terminal 
                -> Putty 
                -> etc 

            -> Open GitBash / Terminal etc 

                -> Navigate to location where private key is present i.e pem file 
                    -> cd downloads 
                -> Set pem file permissions to READ only 
                    -> chmod 400 key 
                -> Use below ssh command to connect with server 
                    -> ssh -i identity_file/private_key username@public-ip-address 

    
    -> NOTE: We are using Linux Servers, which has only CLI (Command Line Interface)

    -> CLI - Command Line Interface

        -> CLI is a powerful tool for interacting with servers 
            through "text based commands" 

        -> CLI is very helpful in Automating Repetitive Tasks 

    
    -> Requirement From Customer 

        -> Create 100 Text files 
        -> Assume you don't have any CLI knowledge 
        -> Then we are left with GUI - Graphical User Interface 
            -> 1 text file creation - 3 seconds 
            -> 100 text file creation - 300 seconds (5 mins)
            -> 100000 text file creation - 300000 seconds (5000 mins) 

    -> Resolving Requirement From Customer Using CLI 

        -> touch file-{1..100}.txt

    -> Hardware & System Software(OS) Commands 

        -> CPU / Processor Info 

            -> cat /proc/cpuinfo 
        
        -> RAM Info 

            -> free -m 

        -> Disk Info 

            -> df -h 

        -> Network  Info 

            -> ip address 

    -> System Software (OS)

        -> uname 
        -> cat /etc/os-release 

    -> Check Running Processes 

        -> ps -ef 
        -> htop (to quit click q on keyboard)

    -> Once Application is Developed 

    -> How Customers Will Access Application ?

        -> Customers Will Access Application Via Servers 

    
    -> To Host / Deploy Applications, Follow Below Approach 

        -> Create Server 

        -> Install Appropriate Softwares On Servers 

        -> Host / Deploy Application On Server 

        NOTE: Above Activities are Operations Oriented 

    -> Web Server 

        -> A web server is computer software [ Nginx HTTP Server ] 
        and underlying hardware [ AWS Instance / AZURE VM ] 
        that accepts requests via HTTP (port 80) 
        to distribute web content.

        -> NOTE: All Servers that host websites must have web server program.

    
    -> Below Work Is More Of System Admin Work 

        -> As Web Server Works On HTTP with Port 80, update the Firewall with HTTP 

    -> Commands to work with Web Application Deployment 

    -> Web Server runs on port 80 

    -> Commands to check, which port is in use by which service 

        -> sudo ss -ntpl 

    -> Install Web Server i.e Nginx HTTP Server 

        -> sudo apt update -y 
        -> sudo apt install nginx -y 
        -> sudo ss -ntpl 
    
    -> Test Web Server 

        -> Browse Public IP 

    -> For Web Servers, we have DocumentRoot i.e location 
        where web pages will be loaded from /var/www/html 

        -> ls /var/www/html 

        -> index page is called Landing Page Of Application

        -> cat /var/www/html/index.nginx-debian.html

        -> Repo URL - https://github.com/ravi2krishna/login-2601.git

        -> Clone Repo Using CLI 

            -> sudo git clone <url> <destination_directory>

            -> sudo git clone https://github.com/ravi2krishna/login-2601.git /var/www/html 

                -> fatal: destination path '/var/www/html' already exists and is not an empty directory.

            -> Clean Up DocumentRoot

                -> ls /var/www/html/
                
                -> sudo rm /var/www/html/index.nginx-debian.html

                -> ls /var/www/html/

                -> sudo git clone https://github.com/ravi2krishna/login-2516.git /var/www/html 

                -> ls /var/www/html/

                    -> README.md  img_avatar2.png  index.html (Success)
                
                -> Browse Public IP 

21st Jan 2026
==============

    -> AZURE Server Setup 

        -> Azure Virtual Machines (VM's) is a part of Azure's cloud-computing platform, 
        Microsoft, that "allows users to rent virtual computers(servers)" 
        on which to run their "own computer applications".

        -> Server                   ==> Azure Virtual Machine (VM)
        -> Server Name              ==> VM Name 
        -> Operating System         ==> Image ( Linux Ubuntu 22.04)
        -> CPU + RAM                ==> Sizes (b1s, b2s etc)           
        -> Login / Authentication   ==> Key Pairs (Public Key & Private Key)
        -> Network                  ==> VNET (Virtual Network)
        -> Firewall                 ==> Network Security Group (Rules: Protocol, Port, Source)
        -> Storage (Hard Disk)      ==> Disk is 30 GB 

        -> Login To AZURE 

            -> http://portal.azure.com/


    -> How To Connect With Server ?

        -> SSH Client Softwares 

            -> A software program which uses SSH to connect with remote linux server 

            -> From Online 
                
                -> https://ssheasy.com/

            -> From Laptop / System Use any one of the below Software 

                -> GitBash (recommended) it provides ssh & also git 
                -> Terminal 
                -> Putty 
                -> etc 

            -> Open GitBash / Terminal etc 

                -> Navigate to location where private key is present i.e pem file 
                    -> cd downloads 
                -> Set pem file permissions to READ only 
                    -> chmod 400 key 
                -> Use below ssh command to connect with server 
                    -> ssh -i identity_file/private_key username@public-ip-address 

    
    -> NOTE: We are using Linux Servers, which has only CLI (Command Line Interface)

    -> CLI - Command Line Interface

        -> CLI is a powerful tool for interacting with servers 
            through "text based commands" 

        -> CLI is very helpful in Automating Repetitive Tasks 

    
    -> Requirement From Customer 

        -> Create 100 Text files 
        -> Assume you don't have any CLI knowledge 
        -> Then we are left with GUI - Graphical User Interface 
            -> 1 text file creation - 3 seconds 
            -> 100 text file creation - 300 seconds (5 mins)
            -> 100000 text file creation - 300000 seconds (5000 mins) 

    -> Resolving Requirement From Customer Using CLI 

        -> touch file-{1..100}.txt

    -> Hardware & System Software(OS) Commands 

        -> CPU / Processor Info 

            -> cat /proc/cpuinfo 
        
        -> RAM Info 

            -> free -m 

        -> Disk Info 

            -> df -h 

        -> Network  Info 

            -> ip address 

    -> System Software (OS)

        -> uname 
        -> cat /etc/os-release 

    -> Check Running Processes 

        -> ps -ef 
        -> htop (to quit click q on keyboard)

    -> Once Application is Developed 

    -> How Customers Will Access Application ?

        -> Customers Will Access Application Via Servers 

    
    -> To Host / Deploy Applications, Follow Below Approach 

        -> Create Server 

        -> Install Appropriate Softwares On Servers 

        -> Host / Deploy Application On Server 

        NOTE: Above Activities are Operations Oriented 

    -> Web Server 

        -> A web server is computer software [ Nginx HTTP Server ] 
        and underlying hardware [ AWS Instance / AZURE VM ] 
        that accepts requests via HTTP (port 80) 
        to distribute web content.

        -> NOTE: All Servers that host websites must have web server program.

    
    -> Below Work Is More Of System Admin Work 

        -> As Web Server Works On HTTP with Port 80, update the Firewall with HTTP 

    -> Commands to work with Web Application Deployment 

    -> Web Server runs on port 80 

    -> Commands to check, which port is in use by which service 

        -> sudo ss -ntpl 

    -> Install Web Server i.e Nginx HTTP Server 

        -> sudo apt update -y 
        -> sudo apt install nginx -y 
        -> sudo ss -ntpl 
    
    -> Test Web Server 

        -> Browse Public IP 

    -> For Web Servers, we have DocumentRoot i.e location 
        where web pages will be loaded from /var/www/html 

        -> ls /var/www/html 

        -> index page is called Landing Page Of Application

        -> cat /var/www/html/index.nginx-debian.html

        -> Repo URL - https://github.com/ravi2krishna/login-2601.git

        -> Clone Repo Using CLI 

            -> sudo git clone <url> <destination_directory>

            -> sudo git clone https://github.com/ravi2krishna/login-2601.git /var/www/html 

                -> fatal: destination path '/var/www/html' already exists and is not an empty directory.

            -> Clean Up DocumentRoot

                -> ls /var/www/html/
                
                -> sudo rm /var/www/html/index.nginx-debian.html

                -> ls /var/www/html/

                -> sudo git clone https://github.com/ravi2krishna/login-2516.git /var/www/html 

                -> ls /var/www/html/

                    -> README.md  img_avatar2.png  index.html (Success)
                
                -> Browse Public IP 

        -> pwd : present working directory

        -> ls : list directory / folder content 

        -> man : manual pages for commands you use (helper utility to know about command)

        -> mkdir : create directory 

        -> touch : create empty file 

        -> cd : change directory 

        -> cat : file content viewer (text, pdf, script, sql, conf etc)

        -> vi / vim (visual editor) is a text editor in linux comes pre-installed 

    -> vi modes 

        -> vi existing_file_name 

            -> vi file.txt 

            -> i - insert mode (insert data)
            -> esc - command mode 
            -> :w - write data 
            -> :wq - write data & quit 

        -> vi new_file (create file)

    -> Shell Scripting 

        -> A shell script is a computer program, or text file, that contains 
        a sequence of commands for a Unix-based operating system's shell 
        (command-line interpreter) to execute automatically. 
        It functions as a program to automate repetitive tasks that a user 
        would otherwise have to type manually into the terminal one command at a time. 

    -> wget https://raw.githubusercontent.com/ravi2krishna/login-2601/refs/heads/main/deploy.sh

    -> ls 

    -> sh deploy.sh

    
23rd Jan 2026
==============

    -> Any Project (Development + Operations)

    -> Login Project is very simple (Has Frontend Only i.e Static WebSite)

        -> https://github.com/ravi2krishna/login-2601.git

    -> Three Tier App Architecture 

        -> Most Popular Applications
            
            -> https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites

    
    -> LMS Application Stack

        -> Database: POSTGRES
        -> Backend: NODEJS 
        -> Frontend: JavaScript (REACTJS)

    -> LMS Project Repository 

        -> https://github.com/ravi2krishna/lms-v1.git

    -> Try Deploying Above Application Like Login App (Deployment FAILED)

    -> Real World Projects like LMS Application goes with following Approach 

        -> Requirement -> Design -> Coding -> Building -> Testing -> Deployment 

        -> From DevOps Point Of View we focus on 

            -> Coding -> Code Analysis (White box Testing) -> Build -> Test (QA Team) -> Deploy 

            -> The above stages in software development makes up CI-CD Pipelines  
    
    
    -> Static Code Analysis - SCA (White box Testing)

        -> Static code analysis is the "process" of examining source code, 
        without executing it to find potential bugs, security vulnerabilities, and 
        quality issues.

        -> Automated tools can scan the code against predefined rules 
        to identify problems early in the development cycle, 
        promoting better coding practices and security. 

        -> Static code analysis involves examining the code for potential issues, 
        vulnerabilities, and adherence to coding standards and best practices. 

        -> Static code analysis can help identify various types of issues, including:

                Syntax errors and typos
                Unused variables and methods
                Code duplication
                Security vulnerabilities (e.g., SQL injection, cross-site scripting)
                Memory leaks and resource leaks
                Performance issues
                Conformance to coding standards and style guidelines (e.g., indentation, naming conventions)

        -> NOTE: Later on we as DevOps Engineers will write Automated CI-CD Pipelines,
                in which SCA is one of the checks / steps 

    -> Earlier to implement "Version Control" Process we used "Git" Tool 

    -> Now to implement "Static Code Analysis" Process we use "SonarQube" Tool 

    -> SonarQube 

        -> SonarQube is an open-source platform for continuous code quality and security analysis 
        that helps developers identify bugs, security vulnerabilities, and code smells in their code. 
        It integrates with CI/CD pipelines.

        -> https://www.sonarsource.com/products/sonarqube/  

    -> SonarQube Requires Following Hardware Configuration
        
            -> AWS 
            
                -> “t2.xlarge instance” i.e 16 GB RAM - 4 CPU’s on AWS, with 20 GB as Storage.  
                
            -> AZURE 
            
                -> D4s_v3, i.e 16 GB RAM - 4 CPU’s on AZURE, with 30 GB as Storage
                
            -> NOTE: Charges Applicable i.e 16 INR per hour

            -> NOTE: SonarQube works on “port 9000”

                -> Make sure to add port 9000 as part of your Security Group or Network Security Group

        -> To Install SonarQube Will Rely On Docker Tool (Docker is for Fastness)

            -> Without Docker - https://github.com/ravi2krishna/sonarqube-installation-guide.git - 45 mins 

            -> With Docker - (5-10) mins Max 

        -> Verify SonarQube Installation

            -> sudo ss -ntpl
            -> Browse SonarQube, in Browser with port 9000 -> ip_address:9000 

        -> For SonarQube Setup, we need Docker 

            docker
            ls
            wget -O get-docker.sh https://get.docker.com && sh get-docker.sh
            ls
            docker   
        
        -> Install SonarQube
            sudo ss -ntpl
            sudo docker container run -dt --name sonarqube --restart=always -p 9000:9000 sonarqube
            sudo ss -ntpl

        -> Browse SonarQube, in Browser with port 9000 -> ip_address:9000 

        -> Default credentials are 
            Username is admin 
            Password is admin

    -> LMS Project Repository 

        -> https://github.com/ravi2krishna/lms-v1.git

    -> Github Fork

        -> Forking a repository means creating a copy of the repo. 
        When you fork a repo, you create your own copy of the repo on your GitHub account.

        -> NOTE: Fork Above Project to your Github Accounts

    -> Performing Code Analysis On LMS Project (Below Link Should be Replaced with your github account )
    
        -> https://github.com/Vignesh-2009/lms-v1.git
        
        ls 
        git clone -b dev https://github.com/Vignesh-2009/lms-v1.git 
        ls 
        ls lms-v1
        cd lms-v1/webapp
        ls 
        sudo docker run  --rm -e SONAR_HOST_URL="http://3.144.15.56:9000" -v ".:/usr/src" sonarsource/sonar-scanner-cli -Dsonar.token=sqp_88e483f8bb4b2d3c1621d556192c055e6c9995e7 -Dsonar.projectKey=lms

    -> NOTE: Once LAB is done with Sonar Analysis, Delete SonarQube Server 


26th Jan 2026
==============

    -> Build Management 

        -> The term "build" may refer to the "process" by which 
        "source code" is converted into "binary code" (software artifact)

        -> In DevOps, the software build process is a foundational component of the 
        Continuous Integration and Continuous Delivery (CI/CD) pipeline, 
        serving as a critical automated step that transforms 
        source code into a deployable product.

        -> Source Code - https://github.com/notepad-plus-plus/notepad-plus-plus/

                -> After Building, Artifact is Useable Software which is below 

        -> Binary Code - https://notepad-plus-plus.org/downloads/

    
    -> Any Build implementation consists of following steps 

        -> Source Code Files 

            -> Source code is the list of human-readable instructions that a programmer writes

            -> Handled by Developer

        -> Metadata File 

            -> File that contains information about the project and 
            configuration details used to build the project. 

            -> Handled by Developer

        -> Binary Code (After Build is done)

            -> Build artifacts are files produced by a build

            -> Handled by Developer in his Laptop
            
            -> Handled by DevOps Engineer on Server for future Automation in CI-CD

        
    -> NOTE: Below Link Help's you understand, how developers initially learn to perform builds 

        -> https://radixweb.com/blog/steps-to-build-react-project-with-create-react-app

    
    -> LMS Project - BUILD 
        
        -> As LMS App is multi tier, We need Following Rules(ports) in Security Group
            -> SSH - 22 - Login
            -> DATABASE TIER [ POSTGRES ] - 5432 - Storing Data
            -> APPLICATION TIER [ NODEJS ] - 8080 - Business Logics
            -> FRONTEND TIER [ REACTJS ] - 80 - Hosted On Web Server

    -> NOTE: LMS Application Build Requires, below hardware configuration

        -> AWS 
            
            -> “t2.medium instance” i.e 4 GB RAM - 2 CPU’s on AWS, with 20 GBas Storage.  
                
        -> AZURE 
            
            -> B2S, i.e 4 GB RAM - 2 CPU’s on AZURE, with 30 GB as Storage

    -> NOTE: Steps To Build LMS Application (From Development Team We Get KT)

    -> sudo ss -ntpl

        -> Setup Database 

            -> Goto https://www.postgresql.org/download/linux/ubuntu/

                sudo apt install curl ca-certificates
                sudo install -d /usr/share/postgresql-common/pgdg
                sudo curl -o /usr/share/postgresql-common/pgdg/apt.postgresql.org.asc --fail https://www.postgresql.org/media/keys/ACCC4CF8.asc
                . /etc/os-release
                sudo sh -c "echo 'deb [signed-by=/usr/share/postgresql-common/pgdg/apt.postgresql.org.asc] https://apt.postgresql.org/pub/repos/apt $VERSION_CODENAME-pgdg main' > /etc/apt/sources.list.d/pgdg.list"
                sudo apt update
                sudo apt install postgresql-18
        
    -> sudo ss -ntpl

    -> Every Database has connection properties, which includes
            -> Address Of Database
            -> Database Port
            -> Database Username
            -> Database Password

        -> Commands to set the password for postgres database
            -> sudo su - postgres
            -> psql
            -> \password
    
    
    -> Setup Backend / App Layer For LMS 

            -> Create a new session for server using "ubuntu" server 

            -> Install Nodejs on your server using below Link 

                -> https://nodesource.com/products/distributions

                    node -v
                    npm -v
                    curl -fsSL https://deb.nodesource.com/setup_22.x | sudo -E bash -
                    sudo apt-get install -y nodejs
                    node -v
                    npm -v

    
    -> Steps to Build Backend API (use "ubuntu" user session)

            -> ls
            -> git clone -b dev https://github.com/joshisuyog4/lms-v1.git 
            -> ls 
            -> cd ~/lms-v1/api
            -> vi .env 

                MODE=dev
                PORT=8080
                DATABASE_URL=postgresql://postgres:db_password@localhost:5432/postgres

                -> NOTE: In .env file we would specify the database connection details.

                    -> grep .env -r
            
            -> Verify in "postgres" user session 

                -> \dt 

            -> Database Schema (Verify in "ubuntu" user session)

                -> cat prisma/migrations/20221110085013_init/migration.sql
            
            -> Commands to setup Database tables (Verify in "ubuntu" user session)

                -> npm install 
                -> npx prisma generate && npx prisma db push
            
            -> Verify in "postgres" user session 

                -> \dt 

            -> NOTE: Command to build application using "ubuntu" user

                -> ls build
                -> npm run build 
                -> ls build

            -> NOTE: Command to start application using "ubuntu" user    
                
                -> node build/index.js 

        -> Verify Backend Status 

            -> Verify with Browser - http://public-ip:8080/api  

            -> NOTE: If you get below message, backend deployment is success   
            
                {"message":"success","mode":"dev"}

    
    -> Setup Frontend / Client Layer For LMS 

        -> In Our Repo, we have "webapp" directory which is frontend part of the application

        -> Create a new session for server using "ubuntu" server 

        -> cd ~/lms-v1/webapp/

        -> vi .env 

            VITE_API_URL=http://public-ip:8080/api

        -> To build frontend

            -> npm install
            -> ls dist
            -> npm run build 
            -> ls dist

        -> To Host Frontend, we need web server 

            -> sudo ss -ntpl
            -> sudo apt -y install nginx
            -> sudo ss -ntpl
            -> ls /var/www/html/
            -> sudo rm -rf /var/www/html/*
            -> ls /var/www/html/
            -> sudo cp -r ~/lms-v1/webapp/dist/*  /var/www/html/
            -> ls /var/www/html/
            -> ls dist 

    
    -> For Troubleshooting 

        -> Check In "ubuntu" user Session

            -> sudo ss -ntpl
            -> sudo systemctl stop postgresql
            -> sudo ss -ntpl
            -> sudo systemctl start postgresql
            -> sudo ss -ntpl

            -> sudo ss -ntpl
            -> go tpt backend session
                -> control + c 
            -> sudo ss -ntpl
            -> node build/index.js
            
            -> Check In "ubuntu" user Session
            -> sudo ss -ntpl
            -> sudo systemctl stop nginx
            -> sudo ss -ntpl
            -> Check Application in Browser
            -> sudo systemctl start nginx
            -> sudo ss -ntpl
            -> Check Application in Browser

    -> NOTE: Terminate Server Once Lab is done 


28th Jan 2026
==============    

    -> Project - 1 

        -> Code -> Build -> Test -> Deploy 

            -> Git & GitHub -> NPM -> SonarQube -> Servers 
    
    -> NOTE: Next Goal is to Implement DevOps Practices / Process On Above Project 

    -> DevOps is a set of PRACTICES that works towards the 
        "AUTOMATION" and "INTEGRATION" of the processes between 
        Software Development (Dev) and IT (Ops) teams, 
        so that organizations can "BUILD", "TEST" and "DEPLOY" softwares/applications 
        "FASTER" and more "RELIABLE"

    -> Whole Project - 1 Took 2-3 Hours 

    -> From DevOps Teams, Organizations are looking for Acceleration i.e "FASTER"

        -> For our earlier experience, using SonarQube(45 Mins), traditionally 

        -> Why shouldn't you Apply Docker on Whole Application Process ??? 

            -> Whole Application Process (Dev & Ops) -> Traditionally Took 2-3 Hours

            -> Whole Application Process (Dev & Ops) -> Docker Took 5-10 mins 

    -> NOTE: To Accelerate Development & Deployment process, we use "Containerization" Practice

    
    -> Project - 2

        -> Implement Acceleration i.e FASTNESS using "Containerization" Practice

    -> Containerization

        -> Containerization is one of the practices in devops, which provides 

            -> "Lightweight" and "Efficient" way of running applications 
            
            -> Promotes "Faster Deployments" and "Portability" for applications

        -> Containerization is implemented by software/tool "DOCKER" 

    -> Container 

        -> An object for holding or transporting something 

            -> https://upload.wikimedia.org/wikipedia/commons/d/df/Container_01_KMJ.jpg

        -> In terms of software development, a container is an object 
        for holding or transporting/shipping applications.

            -> https://cdn.prod.website-files.com/67615512eed3697e5e735df6/67c1d375b94ef6458106170b_vrGMCnHTQY2TKkXLNFbx.jpeg

    -> Monolithic Architecture

        -> Monolithic architecture is a software design pattern where the entire application 
        is built as a "single, indivisible unit".

    -> Micro Services Architecture

        -> Microservices Architecture is a software development approach that involves 
        building "small, independent services" that work together to create a larger application.
    
    -> https://miro.medium.com/v2/resize:fit:1400/1*rW3dglWAkRhnPpMrnacQ-g.png

    -> NOTE: As DevOps Engineer, Deploying Micro Sized Applications(Micro Services) on Containers 
    is our primary work on projects 

    
    -> Docker Architecture

        -> Docker Client (CLI)  

        -> Docker Server (Daemon)

        -> Docker Registry (https://hub.docker.com)

        -> Docker Images

        -> Docker Containers 

        -> https://assets.bytebytego.com/diagrams/0414-how-does-docker-work.png


        -> Python is Programming Language 
        -> SonarQube is Code Analysis Tool 
        -> Ubuntu is Operating System 
        -> Postgres is Database 

        -> NOTE: All Above are present in Docker Registry (https://hub.docker.com)

        -> NOTE: In Terms of Docker all the above are considered as "Docker Images"

        -> Python is an Image
        -> SonarQube is an Image
        -> Ubuntu is an Image
        -> Postgres is an Image

        -> NOTE: All the above images are stored in Docker Registry (https://hub.docker.com)
        like Different Applications in Play Store

    -> Docker Containers are Runtime of images 

            -> Images are like Templates / Blueprints

            -> Containers are Real Entities We run

            -> NOTE: To create a container, image is mandatory 

        -> A container is an object for holding or transporting/shipping applications.

            -> To Create Container, we use Docker Client (CLI) and make a request 

            -> DevOps Engineer -> Makes Request For Creating Container Using Docker Client (CLI)

                -> Docker Client (CLI) -> Sends Request To Docker Server (Daemon) -> Daemon Connects To Docker Registry

                    -> Fetch Docker Images to Server(compute) -> Using Image Daemon Runs/Creates Containers


        -> The Daemon/Service is responsible for managing Docker objects 
            such as images, containers, and networks. All the heavy lifting is done by daemon.
        
        -> The client sends commands to the daemon and receives output. 
        
        -> The registry stores Docker images and allows them to be shared among users and systems.

        -> A Docker image is a lightweight, standalone, and executable package 
            that includes everything needed to run the desired software application.

        -> A container in Docker allows you to run an application with all the dependencies it needs. 
            To create a container we need Docker Image.

        -> NOTE: Without Proper Understanding Of Docker we cannot work with "Kubernetes"

        -> NOTE: Prerequisite Of Kubernetes is Docker

    
    
    -> Docker Setup 

        -> AWS 
            
            -> “t2.medium instance” i.e 4 GB RAM - 2 CPU’s on AWS, with 20 GB as Storage.  
                
        -> AZURE 
            
            -> B2S, i.e 4 GB RAM - 2 CPU’s on AZURE, with 30 GB as Storage

        -> Add Following Rules in Security Groups / Network Security Groups
            -> 22, 80, 32768-61000, 8080-9090

                -> 32768-61000 - Docker Pre defined port range(*)   
                -> 8080-9090 - User defined port range (Based on your Requirement)

        -> Setup Docker 

            -> docker 
            -> wget -O get-docker.sh https://get.docker.com && sh get-docker.sh
            -> docker

        -> Check Docker Images On Host 

            -> docker image ls
            -> permission denied

        -> To Overcome Permissions issues, add ubuntu user to docker group 
            
            -> sudo usermod -aG docker ubuntu
            -> newgrp docker

        -> Check Docker Containers On Host 

            -> docker container ls -a 

        -> Create Docker Containers On Host 

            -> docker container run --name c1 <image>

            -> docker container run --name c1 hello-world 

30th Jan 2026
==============

    -> To Run Containers we have Modes 

        -> No Mode 

            -> Containers are in exit state i.e stopped 

            -> docker container run --name c1 ubuntu

                -> Name Conflict & Latest Tag 

            -> docker container run --name c3 ubuntu

        
        -> Interactive Mode / Foreground Mode (development / troubleshoot)

            -> docker container run -it --name c4 ubuntu

            -> cat /etc/os-release

            -> Verify By Opening One More Sessions for Server 

                -> docker container ls -a

            -> NOTE: In Interactive Mode Containers will stop, once we come out of the container

            -> NOTE: Containers are "Lightweight" and "Efficient" 

                -> docker container run -it --name c5 ubuntu:22.04 

                -> cat /etc/os-release

                -> Run following command on host 

                    -> ps -ef 

                -> Run following command on c5 container 

                    -> ps -ef 

                    -> ssh 

                    -> git

                    -> ss 

            -> NOTE: As we have Microservices, we need micro sized Environments 
            i.e containers using images which has only what is required 

        
        -> Detached Mode / Background Mode (Production)

            -> docker container run -dt --name c6 ubuntu:22.04 

            -> docker container ls -a

            -> NOTE: In Detached Mode Containers will never stop, unless we explicitly stop

            -> docker container exec <container-name> <command> 

            -> docker container exec c6 cat /etc/os-release

            -> docker container exec c6 ps -ef 

            -> docker container run -it --name c7 ubuntu:22.04 

            -> docker container exec -it c6 bash 

                -> exit 

    
    -> Container Management Commands 

        -> Server: Create / Start / Stop / Remove 

        -> Containers: Create / Start / Stop / Remove 

            -> docker container rm <container-name>
            -> docker container rm <container-id>

            -> docker container stop <container-name>

            -> docker container start <container-name>

            -> docker container rm -f <container-name>

        -> Another Approach To Create Containers 

            -> docker pull ubuntu:25.04 

            -> docker container create -it --name c10 ubuntu:25.04 
            -> docker container start --attach -i c10


    -> Goal: Run Web Application In Container, like we did in Server / VM  

        -> Procedure in Server / VM 

            -> Create Server / VM 
            -> Update The System 
            -> Install Nginx Web Server 
            -> Fetch Application Code
            -> Deploy Application On Nginx Web Server 

        -> Procedure in Container (Why) 

            -> NOTE: Containers are "Lightweight" and "Efficient" 

            -> docker container run -dt --name web-app ubuntu:22.04 
            -> docker container ls -a
            -> ss -ntpl 
            -> docker container exec -it web-app bash 
            -> ss -ntpl 
            -> apt update -y 
            -> apt install iproute2 -y 
            -> ss -ntpl 
            -> apt install nginx -y 
            -> service nginx start 
            -> ss -ntpl 

            -> Check properties Of container using 

                -> docker container inspect web-app
                    -> "IPAddress": "172.17.0.2"

                -> curl 172.17.0.2

1st Feb 2026
==============

    -> NOTE: Above approach is not a recommended way, but it connects 
    how we shifted from VM to Container.

    -> docker container rm -f web-app

    -> docker container run -dt --name web-app ubuntu:22.04 

    -> docker container inspect web-app

    -> curl 172.17.0.2

    -> docker container exec -it web-app bash 

    -> service nginx start 

    -> ss -ntpl 

    -> NOTE: Above approach is not a recommended way, as we need to 
    setup nginx from scratch again 

    
    -> NOTE: Below approach is a recommended way

        -> docker container run -dt --name web-app-new nginx 

        -> docker container ls -a

        -> docker container inspect web-app-new 

        -> curl 172.17.0.3

        -> docker container exec web-app-new cat /etc/os-release 

    -> NOTE: 

        -> docker container rm -f web-app

        -> docker container rm -f web-app-new 

        -> docker container run -dt --name web-app ubuntu:22.04 

        -> docker container inspect web-app

        -> curl 172.17.0.2

        -> docker container run -dt --name web-app-new nginx 

        -> docker container inspect web-app-new 

        -> curl 172.17.0.3

    -> Browse Public-IP (No access to Nginx Page)

        -> As nginx is running on the container, not on the host 

        -> Now how can we make customers access web applications from internet ??

    -> To Access Containers Outside i.e internet we need to understand docker networking

    -> Docker supports following network drivers, each designed for specific use case
        
        -> Host
        -> None
        -> Bridge

    -> docker network ls 

    -> docker container ls -a

    -> docker container inspect web-app

    -> docker container inspect web-app-new 

    -> docker network inspect bridge  

    -> NOTE: By Default, Containers will run on "bridge" network 

    -> Host Network Driver

        -> This driver removes network isolation between the container and the Docker host, 
        allowing them to share the host’s networking namespace

        -> docker network inspect host   

        -> docker container run -dt --name web-app-host --network=host nginx 

        -> docker container ls -a

        -> docker network inspect host   

        -> docker container inspect web-app-host

        -> docker container inspect web-app

        -> docker container inspect web-app-new 

        -> docker container inspect web-app-host

    -> NOTE: Check below command 

        -> docker container run -dt --name web-app-login --network=host nginx 

        -> docker container ls -a

    -> NOTE: Check Container logs using 

        -> docker container logs <Container-name> 

        -> docker container logs web-app-login

            -> nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)

            -> NOTE: Fix is upcoming bridge network 

    
    -> None Network Driver

        -> This driver removes network access to containers i.e no network (no www)

            -> docker container ls -a
            -> docker container exec web-app apt update -y 
            -> docker container exec web-app-host apt update -y 
            -> docker network inspect none
            -> docker container run -dt --name web-app-none --network=none nginx 
            -> docker container ls -a
            -> docker network inspect none    
            -> docker container exec web-app-none apt update -y 

        -> NOTE: This confirms we have no network access in none network mode 

    
    -> Bridge Network Driver

        -> The default network driver for containers. 
        When a new container is run, it can be attached to this Bridge network.

        -> Using bridge network we can run multiple containers at same time, 
        but cannot be accessed outside via internet. 

        -> To Allow External Access To Containers using bridge, we can use Port Forwarding (-p)

        -> Port Forwarding: This is the activity that makes a "port inside a container" 
            accessible to "ports on the Docker host" for external access.

            -> -P docker ephemeral ports ( predefined range 32768 to 61000 )

            -> docker container run -dt --name web-app-one nginx 

            -> docker container ls -a

            -> docker container inspect web-app-one

            -> docker container run -dt --name web-app-two -P nginx 

            -> docker container ls -a

            -> docker container inspect web-app-two 

            -> docker container inspect web-app-one

            -> Browse Public-IP:32768

            -> docker container run -dt --name web-app-three -P nginx 

            -> docker container ls -a

            -> Browse Public-IP:32769 

            -> docker container run -dt --name web-app-four -P nginx 

            -> docker container ls -a

            -> Browse Public-IP:32770

    -> NOTE: -p docker user defined ports ( user defined range for me is 8080-9090 )

        -> docker container run -dt --name web-app-five -p 8080:80 nginx 

        -> docker container ls -a

        -> Browse Public-IP:8080 

        -> docker container run -dt --name web-app-six -p 8085:80 nginx 

        -> docker container ls -a

        -> Browse Public-IP:8085 

    -> NOTE: Earlier we used below command 

        -> docker container run -dt --name sonarqube --restart=always -p 9000:9000 sonarqube


4th Feb 2026
==============

    -> Data Persistency 

        -> Persistent Means Permanent Storage

        -> Non-Persistent Means Temporary Storage

    -> NOTE: By default containers are "non-persistent"(ephemeral) in nature
    This design makes containers lightweight, portable, and 
    easy to scale or replace, which is ideal for "stateless" applications. 

    -> Goal: Deploy Login Application

        -> https://github.com/ravi2krishna/login-2601.git

        -> Before Getting Started remove all existing containers 

            -> docker container rm -f $(docker container ps -aq)

            -> docker container ls -a
       
        -> docker container run -dt --name login-app-1 -p 8080:80 nginx 

        -> Above command gives only Nginx, but we need Login App 

        -> docker container exec -it login-app-1 bash 

        -> ls /var/www/html/

        -> NOTE: Above directory is valid in Servers but not in containers 

        -> Inside containers created with Nginx Image use below location for hosting code

            -> ls /usr/share/nginx/html

        -> git clone https://github.com/ravi2krishna/login-2601.git /usr/share/nginx/html

        -> apt update -y 
        -> apt install git -y 

        -> git clone https://github.com/ravi2krishna/login-2601.git /usr/share/nginx/html

            -> fatal: destination path '/usr/share/nginx/html' already exists and is not an empty directory.

            -> Clean Up DocumentRoot

                -> ls /usr/share/nginx/html
                
                -> rm -rf /usr/share/nginx/html/* 

                -> ls /usr/share/nginx/html

        -> git clone https://github.com/ravi2krishna/login-2601.git /usr/share/nginx/html

        -> Test by Browsing ip address of server
        
            -> exit 

        -> Let's remove the container and check back again by Browsing ip address of server

            -> docker container rm -f login-app-1 
            -> Browse ip address of server

        -> Create Login App Container again

            -> docker container run -dt --name login-app-1 -p 8080:80 nginx 

            -> docker container ls -a

            -> Browse ip address of server

        -> NOTE: With above observation, we can say, when we remove container 
        all data associated with container is lost 
        
        -> To achieve Persistency with data inside containers use "Docker Volumes"

    
    -> Docker Volumes

        -> Docker volumes is a mechanism for "persisting data" generated by Docker containers.  

        -> Docker volumes allow data to persist even when containers are deleted. 

        -> Data Persistency For Login App 

            -> docker volume ls 
            -> docker container rm -f login-app-1
            -> docker container run -dt --name login-app-1 -p 8080:80 -v login_app:/usr/share/nginx/html nginx 
            -> docker container ls -a
            -> docker volume ls 
            -> NOTE: The Above volume is on host 
            -> docker volume inspect login_app
            -> sudo ls /var/lib/docker/volumes/login_app/_data

            -> docker container exec -it login-app-1  bash
            -> apt update -y 
            -> apt install git -y 
            -> rm -rf /usr/share/nginx/html/*    
            -> git clone https://github.com/ravi2krishna/login-2601.git /usr/share/nginx/html
            -> exit 
            -> sudo ls /var/lib/docker/volumes/login_app/_data


        -> Let's confirm volume helped us persist data ?

            -> docker container rm -f login-app-1
            -> docker container ls -a
            -> Browse ip address of server
            -> docker volume ls 
            -> sudo ls /var/lib/docker/volumes/login_app/_data
            -> docker container run -dt --name login-app-1 -p 8080:80 -v login_app:/usr/share/nginx/html nginx 
            -> docker container exec login-app-1 ls /usr/share/nginx/html
            -> Browse ip address of server

    -> NOTE: Now say our system encountered downtime (because of hardware failure)

        -> Next step is create a new server in a different data center and host application

            -> Launch New Server & Install Docker 

            -> docker container run -dt --name login-app-1 -p 8080:80 -v login_app:/usr/share/nginx/html nginx

            -> Test by Browsing ip address of server

            -> NOTE: Login Application is not working 

        -> NOTE: With above observation, we can say, volumes creates dependencies
        which breaks the principal of "Portability"

        -> NOTE: Now we want "Portability" and "Data" required for Application to work 

    

    -> Dockerize Applications / Build Custom Docker Images

        -> The process of Dockerizing an application involves creating a Dockerfile, 
        building a Docker image, and running the application as a Docker container.

        -> NOTE: Suggestion given from Official Nginx Image https://hub.docker.com/_/nginx

            -> Alternatively, a simple Dockerfile can be used to generate a new image 
            that includes the necessary content (which is a much cleaner solution than 
            the bind mount/volume above)

        -> Dockerize an application is the process of converting an application to run 
        within a Docker container without any dependencies

        -> Docker can build images automatically by reading the instructions from a "Dockerfile"

    -> Dockerfile 

        -> A Dockerfile is a text document that contains all the commands 
        a user could call on the command line to assemble an image. 
        
        -> Dockerfile is source code for Docker Image.

            -> Nginx Dockerfile - https://github.com/nginx/docker-nginx/blob/a306285ea2e4267c63ca539c66e8bc242bdce917/mainline/debian/Dockerfile

    
    -> Dockerize an application requires following Flow

            -> create a Dockerfile with the required instructions in your project i.e repository

            -> use the "docker build" command to create a Docker image 

            -> Then you can run the container using the image built for confirmation 

            -> https://miro.medium.com/v2/1*eh-tX75FFzQffFhCfCZaMA.png


6th Feb 2026
==============

    -> Dockerize Login Application

        -> ls 
        -> git clone https://github.com/ravi2krishna/login-2601.git
        -> ls 
        -> cd ~/login-2601
        -> ls 
        -> ls Dockerfile 
        -> docker build -t username_docker_hub/image_name . 
        -> Create Account On Docker Hub 
        -> docker build -t ravi2krishna/login-2601 . 
            -> ERROR: failed to build: open Dockerfile: no such file or directory
        -> touch Dockerfile
        -> ls Dockerfile
        -> docker build -t ravi2krishna/login-2601 . 
            -> ERROR: failed to build: failed to solve: the Dockerfile cannot be empty
        -> cat Dockerfile
            -> please build image
        -> docker build -t ravi2krishna/login-2601 . 
            -> ERROR: failed to build: dockerfile parse error on line 1: 
            unknown instruction: please

    -> NOTE: To Build Docker Images, we need to follows Docker Instructions only 

    -> Docker Instructions / Docker Directives 

        FROM — set base image
        COPY — copy files to image
        RUN — execute command in container
        WORKDIR — set working directory
        VOLUME — create mount-point for a volume
        CMD — set executable for container
        EXPOSE — set port number 
        ENV — set environment variable

    -> NOTE: Check Nginx Official page of docker hub - https://hub.docker.com/_/nginx

    -> cat Dockerfile
        # - Means Commnet, ignored by docker
        # FROM - To Set Base Functionality
        FROM nginx

        # COPY - To Copy Files from host to above image
        COPY . /usr/share/nginx/html
    
    -> docker image ls 
    -> docker build -t ravi2krishna/login-2601 . 
    -> docker image ls 
    
    -> docker container run -dt --name login-app -p 8080:80 ravi2krishna/login-2601
    -> docker container ls -a
    -> Browse ip address of server

    -> Currently the custom image is on host, to get Portability Upload /  Push
    image to Docker Hub 

        -> In Docker Hub, create Token 
        -> Follow the commands given 
            -> docker login -u ravi2krishna
            -> paste token 
        -> docker push ravi2krishna/login-2601
        -> NOTE: Verify the image in Docker Hub 
    
    -> NOTE: Remove all containers and all images and test login app by 
    Creating Container Using Image available in Docker Hub ravi2krishna/login-2601

        -> docker container rm -f $(docker container ps -aq)
        -> docker container ls -a
        -> docker image ls
        -> docker image rm -f $(docker image ls -aq)
        -> docker image ls
        -> remove application code too 
        -> cd ~
        -> rm -rf login-2601
        -> ls 
    
    -> NOTE: If below command works and loads application in Browser,
    We have successfully created custom image 

        -> docker container run -dt --name login-app -p 8080:80 ravi2krishna/login-2601

    -> NOTE: New Requirements Came -> New Code -> Rebuild Image with tags -> Create Container

    -> New Requirement

        -> Student Login Form 
        -> Trainer Login Form 
        -> Admin Login Form 

        -> Created New branches like Student, Trainer & Admin, 
        made code changes and pushed to Github 

    -> Student Release 

        -> git clone -b student https://github.com/ravi2krishna/login-2601.git
        -> cd ~/login-2601
        -> docker image ls
            -> ravi2krishna/login-2601:"latest"
        -> docker build -t ravi2krishna/login-2601:student . 
        -> docker image ls
        -> docker push ravi2krishna/login-2601:student
        -> docker container run -dt --name student-login-app -p 8081:80 ravi2krishna/login-2601:student 
        -> docker container ls -a 

    -> Trainer Release 

        -> git clone -b trainer https://github.com/ravi2krishna/login-2601.git
        -> cd ~/login-2601
        -> docker image ls
            -> ravi2krishna/login-2601:"latest"
        -> docker build -t ravi2krishna/login-2601:trainer . 
        -> docker image ls
        -> docker push ravi2krishna/login-2601:trainer
        -> docker container run -dt --name trainer-login-app -p 8082:80 ravi2krishna/login-2601:trainer 
        -> docker container ls -a 

    
    -> Now we are ready to Dockerize LMS Application 

        -> LMS Application Deployment Process is 2-3 Hours 

        -> Our Goal for project 2 is to Accelerate Process i.e Deployment Process is 2-3 Mins 

    -> Dockerize LMS Application / Dockerize Any Three Tier Architecture Application

        -> REACTJS + Nodejs + Postgres
        -> Before beginning with project clean up existing resources 
            -> docker container rm -f $(docker container ps -aq)
        
        -> sudo ss -ntpl
            -> No Ports 80, 8080, 5432 

        -> Setup Postgres Database Using Docker 

            -> docker container run -dt --name lms-db -e POSTGRES_PASSWORD=Login@123 postgres 
            -> docker container ls -a 

        -> Setup Nodejs Environment Using Docker 

            -> docker container run -dt --name t1 node:22 
            -> docker container ls -a 
            -> docker container exec t1 node -v 
            -> docker container exec t1 npm -v 

        -> Steps To Build Custom LMS Backend Image 

            -> ls
            -> cd ~
            -> git clone -b dev https://github.com/ravi2krishna/lms-v1.git 
            -> ls 
            -> cd ~/lms-v1/api
            -> vi .env 
                MODE=dev
                PORT=8080
                DATABASE_URL=postgresql://postgres:db_password@localhost:5432/postgres
            
            -> docker container inspect lms-db
                -> update the ip of lms-db container in .env file 

            -> vi .env 
                MODE=dev
                PORT=8080
                DATABASE_URL=postgresql://postgres:Login@123@172.17.0.2:5432/postgres
            
            -> rm Dockerfile 
                -> (old existing Dockerfile we removed)
            
            -> vi Dockerfile 

                # Base Image
                FROM node:22

                # RUN - runs commands
                RUN mkdir /backend

                # WORKDIR - set path as working directory
                WORKDIR /backend

                # COPY - copy code
                COPY . /backend

                # RUN - Build Related Commands
                RUN npm install
                RUN npx prisma generate
                RUN npx prisma db push
                RUN npm run build

                # Start Application
                # RUN node build/index.js
                CMD ["node","build/index.js"]


            -> docker build -t ravi2krishna/lms-be . 
            -> docker image ls 
            -> docker container run -dt --name lms-be -p 8080:8080 ravi2krishna/lms-be 
            -> docker container ls -a 

            -> Verify Backend Status 

            -> Verify with Browser - http://public-ip:8080/api  

            -> NOTE: If you get below message, backend deployment is success   
            
                {"message":"success","mode":"dev"}

            -> docker push ravi2krishna/lms-be 


        -> Steps To Build Custom LMS Frontend Image 

            -> cd ~/lms-v1/webapp/

            -> rm Dockerfile 
                -> (old existing Dockerfile we removed)

            -> vi .env 

                VITE_API_URL=http://public-ip:8080/api

            -> vi Dockerfile

                # Base Image
                FROM node:22 AS build

                # RUN - runs commands
                RUN mkdir /frontend

                # WORKDIR - set path as working directory
                WORKDIR /frontend

                # COPY - copy code
                COPY . /frontend

                # RUN - Build Related Commands
                RUN npm install
                RUN npm run build

                # Deploy Application On Nginx
                FROM nginx

                # COPY
                COPY --from=build /frontend/dist /usr/share/nginx/html

            -> docker build -t ravi2krishna/lms-fe . 
            -> docker image ls 
            -> docker container run -dt --name lms-fe -p 80:80 ravi2krishna/lms-fe 
            -> docker container ls -a 

            -> Verify Frontend with Browser - http://public-ip:80

            -> docker push ravi2krishna/lms-fe 

    -> NOTE: In future i want to run LMS Applicable

        -> docker container run -dt --name lms-db -e POSTGRES_PASSWORD=Login@123 postgres 
        -> docker container run -dt --name lms-be -p 8080:8080 ravi2krishna/lms-be 
        -> docker container run -dt --name lms-fe -p 80:80 ravi2krishna/lms-fe 